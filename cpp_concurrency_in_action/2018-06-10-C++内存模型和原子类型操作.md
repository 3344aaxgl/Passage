---
layout: post
title:  "C++内存模型和原子类型操作"
date:   2018-06-10 22:03:51 +0800
categories: cpp_concurrency_in_action
tags: c++
description: cpp concurrency in action读书笔记
---

## 5.1 内存模型基础

这里从两方面来讲内存模型:一方面是基本结构,这与事务在内存中是怎样布局的有关;另一方面就是并发。

### 5.1.1 对象和内存位置

1. 每一个变量都是一个对象，包括作为其成员变量的对象。
2. 每个对象至少占有一个内存位置。
3. 基本类型都有确定的内存位置(无论类型大小如何，即使他们是相邻的，或是数组的一部
分)。
4. 相邻位域是相同内存中的一部分。

### 5.1.2 对象、内存位置和并发

为了避免条件竞争，两个线程就需要一定的执行顺序。第一种方式，如第3章所述那样，使用互斥量来确定访问的顺序；当同一互斥量在两个线程同时访问前被锁住，那么在同一时间内就只有一个线程能够访问到对应的内存位置，所以后一个访问必须在前一个访问之后。另一种方式是使用原子操作同步机制，决定两个线程的访问顺序。

### 5.1.3 修改顺序

投机执行是不允许的，因为当线程按修改顺序访问一个特殊的输入，之后的读操作，必须由线程返回较新的值，并且之后的写操作必须发生在修改顺序之后。同样的，在同一线程上允许读取对象的操作，要不返回一个已写入的值，要不在对象的读取后再写入另一个值。

## 5.2 C++ 中的原子操作和原子类型

原子操作是个不可分割的操作。在系统的所有线程中，你是不可能观察到原子操作完成了一半这种情况的；它要么就是做了，要么就是没做，只有这两种可能。

### 5.2.1 标准原子类型

标准原子类型定义在头文件 <atomic> 中。这些类型上的所有操作都是原子的，在语言定义中只有这些类型的操作是原子的，不过可以用互斥锁来模拟原子操作。实际上，标准原子类型自己的实现就可能是这样模拟出来的：它们(几乎)都有一个 is_lock_free() 成员函数，这个函数让用户可以查询某原子类型的操作是直接用的原子指令( x.is_lock_free() 返回 true )， 还是编译器和库内部用了一个锁( x.is_lock_free() 返回 false )。

只有std::atomic_flag 类型不提供is_lock_free()成员函数。这个类型是一个简单的布尔标志，并且在这种类型上的操作都需要是无锁的；在 std::atomic_flag 对象明确初始化后，做查询和设置(使用test_and_set()成员函数)，或清除(使用clear()成员函数)都很容易。

剩下的原子类型都可以通过特化 std::atomic<> 类型模板而访问到，并且拥有更多的功能，但可能不都是无锁的。

标准原子类型是不能拷贝和赋值，他们没有拷贝构造函数和拷贝赋值操作。但是，因为可以隐式转化成对应的内置类型，所以这些类型依旧支持赋值，可以使用load()和store()成员函数，exchange()、compare_exchange_weak()和compare_exchange_strong()。它们都
支持复合赋值符：+=, -=, *=, |= 等等。并且使用整型和指针的特化类型还支持 ++ 和 --。当
然，这些操作也有功能相同的成员函数所对应：fetch_add(), fetch_or() 等等。

std::atomic<> 类模板不仅仅一套特化的类型，其作为一个原发模板也可以使用用户定义类型创建对应的原子变量。因为，它是一个通用类模板，操作被限制为load(),store()(赋值和转换为用户类型), exchange(), compare_exchange_weak()和compare_exchange_strong()。

每种函数类型的操作都有一个可选内存排序参数，这个参数可以用来指定所需存储的顺序。

1. Store操作，可选如下顺序：memory_order_relaxed, memory_order_release,
memory_order_seq_cst。
2. Load操作，可选如下顺序：memory_order_relaxed, memory_order_consume,
memory_order_acquire, memory_order_seq_cst。
3. Read-modify-write(读-改-写)操作，可选如下顺序：memory_order_relaxed,
memory_order_consume, memory_order_acquire, memory_order_release,
memory_order_acq_rel, memory_order_seq_cst。所有操作的默认顺序都是memory_order_seq_cst。

### 5.2.2 std::atomic_flag的相关操作

std::atomic_flag 是最简单的标准原子类型，它表示了一个布尔标志。这个类型的对象可以在两个状态间切换：设置和清除。

std::atomic_flag 类型的对象必须被ATOMIC_FLAG_INIT初始化。std::atomic_flag可以销毁，清除或设置。这些事情对应的函数分别是：clear()成员函数，和test_and_set()成员函数。clear()和test_and_set()成员函数可以指定好内存顺序。clear()是一个存储操作，所以不能有memory_order_acquire或memory_order_acq_rel语义，但是test_and_set()是一个“读-改-写”操作，所有可以应用于任何内存顺序标签。每一个原子操作，默认的内存顺序都是memory_order_seq_cst。

{% highlight c++ %}

class spinclock_mutex
{
  private:
    std::atomic_flag flag;
  public:
    spinclock_mutex():flag(ATOMIC_FLAG_INIT)
    {

    }

    void lock()
    {
        while(flag.test_and_set(std::memory_order_acquire));
    }

    void unlock()
    {
        flag.clear(std::memory_order_release);
    }
};

void fun(int n, spinclock_mutex &sp)
{
    for (int i = 0; i < 100; i++)
    {
        sp.lock();
        std::cout << "Now it's thread " << n << '\n';
        sp.unlock();
    }
}

void test_spinlock()
{
    spinclock_mutex sp;
    std::vector<std::thread> v;
    for(int i = 0; i < 10; i++)
      //传入入参，调用构造函数
      v.emplace_back(fun,i,std::ref(sp));
    
    for(auto& t : v)
      t.join();
}
{% endhighlight %}

### 5.2.3 std::atomic的相关操作

使用store()去写入(true或false)还是好于std::atomic_flag中限制性很强的clear()。同样的，test_and_set()函数也可以被更加通用的exchange()成员函数所替换，exchange()成员函数允许你使用你新选的值替换已存储的值，并且自动的检索原始值。std::atomic<bool> 也支持对值的普通(不可修改)查找，其会将对象隐式的转换为一个普通的bool值，或显示的调用load()来完成。

“比较/交换”操作是原子类型编程的基石；它比较原子变量的当前值和一个期望值，当两值相等时，存储提供值。当两值不等，期望值就会被更新为原子变量中的值。

对于compare_exchange_weak()函数，当原始值与预期值一致时，存储也可能会不成功；在这个例子中变量的值不会发生改变，并且compare_exchange_weak()的返回是false。

另一方面，如果实际值与期望值不符，compare_exchange_strong()就能保证值返回false。

一次失败的“比较/交换”将不会进行存储，所以“比较/交换”操作不能拥有memeory_order_release或memory_order_acq_rel语义。

你也不能提供比成功顺序更加严格的失败内存顺序；当你需要memory_order_acquire或memory_order_seq_cst作为失败语序，那必须要如同“指定它们是成功语序”那样去做。如果你没有指定失败的语序，那就假设和成功的顺序是一样的.

std::atomic<bool> 和 std::atomic_flag 的不同之处在于， std::atomic<bool> 不是无锁的；
为了保证操作的原子性，其实现中需要一个内置的互斥量。当处于特殊情况时，你可以使用is_lock_free()成员函数，去检查 std::atomic<bool> 上的操作是否无锁。这是另一个，除了 std::atomic_flag 之外，所有原子类型都拥有的特征。

{% highlight c++ %}

bool expect = true;
std::atomic_bool b;
while(!b.compare_exchange_weak(expect,false));
{% endhighlight %}

### 5.2.4 std::atomic:指针运算

原子指针类型，可以使用内置类型或自定义类型T，通过特化 std::atomic<T*> 进行定义。不能拷贝构造，
也不能拷贝赋值，但是他可以通过合适的类型指针进行构造和赋值。如同成员函数is_lock_free()一样， std::atomic<T*> 也有load(), store(), exchange(),compare_exchange_weak()和compare_exchage_strong()成员函数。std::atomic<T*> 为指针运算提供新的操作。基本操作有fetch_add()和fetch_sub()提供，它们在存储地址上做原子加法和减法，为+=, -=, ++和--提供简易的封装。

{% highlight c++ %}

Foo f[5];
std::atomic<Foo*> p(f);
Foo* x = p.fetch_add(2);
assert(x == f);
assert(p.load() == &f[2]);
x = (p -= 1);
assert(x == &f[1]);
assert(p.load() == &f[1]);
{% endhighlight %}

### 5.2.5 标准的原子整型的相关操作

如同普通的操作集合一样(load(), store(), exchange(), compare_exchange_weak(), 和
compare_exchange_strong())，在 std::atomic<int> 和 std::atomic<unsigned long long> 也是有一套完整的操作可以供使用：fetch_add(), fetch_sub(), fetch_and(), fetch_or(),fetch_xor()，还有复合赋值方式((+=, -=, &=, |=和^=)，以及++和--(++x, x++, --x和x--)。

### 5.2.6 std::atomic<>主要类的模板

为了使用 std::atomic<UDT> (UDT是用户定义类型)：
* 这个类型必须有拷贝赋值运算符。这就意味着这个类型不能有任何虚函数或虚基类，以及必须使用编译器创建的拷贝赋值操作。不仅仅是这些，自定义类型中所有的基类和非静态数据成员也都需要支持拷贝赋值操作。
* 这(基本上)就允许编译器使用memcpy()，或赋值操作的等价操作，因为它们的实现中没有用户代码。
* 最后，这个类型必须是“位可比的”(bitwise equality comparable)。

![7.png](7.png)

### 5.2.7 原子操作的释放函数

在不同的原子类型中
也有等价的非成员函数存在。大多数非成员函数的命名与对应成员函数有关，但是需要“atomic_”作为前缀(比如， std::atomic_load() )。这些函数都会被不同的原子类型所重载。在指定一个内存序列标签时，他们会分成两种：一种没有标签，另一种将“_explicit”作为后缀，并且需要一个额外的参数，或将内存顺序作为标签，亦或只有标签。参数传入指针。

{% hihghlight c++ %}
std::shared_ptr<Foo> p;
void process_global_data()
{
    std::shared_ptr<Foo> local = std::atomic_load(&p);
}
void update_global_data()
{
    std::shared_ptr<Foo> local(new Foo);
    std::atomic_store(&p, local);
}
{% endhighlight %}

## 5.3 同步操作和强制排序

{% highlight c++ %}

void reader_thread()
{
    while(!data_ready.load());                    //1
    std::cout<<"The answer="<<data[0]<<'\n';      //2
}

void writer_thread()
{
    data.push_back(42);                           //3
    data_ready.store(true);                       //4
}
{% endhighlight %}

强制访问顺序是由对 std::atomic<bool> 类型的data_ready变量进行操作完成的；这些操作通过先行发生(happens-before)和同步发生(synchronizes-with)确定必要的顺序。写入数据③的操作，在写入data_ready标志④的操作前发生，并且读取标志①发生在读取数据②之前。当data_ready①为true，写操作就会与读操作同步，建立一个“先行发生”关系。因为“先行发生”是可传递的，所以写入数据③先行于写入标志④，这两个行为又先行于读取标志的操作①，之前的操作都先行于读取数据②。

### 5.3.1 同步发生

“同步发生”只能在原子类型之间进行操作。“同步发生”的基本想法是：在变量x进行适当标记的原子写操作W，同步与对x进行适当标记的原子读操作，读取的是W操作写入的内容；或是在W之后，同一线程上的原子写操作对x写入的值；亦或是任意线程对x的一系列原子读-改-写操作。

如果线程A存储了一个值，并且线程B读取了这个值，线程A的存储操作与线程B的载入操作就是同步发生的关系

### 5.3.2 先行发生

“先行发生”关系是一个程序中，基本构建块的操作顺序；它指定了某个操作去影响另一个操作。

{% highlight c++ %}

void fun(int a,int b)
{
    std::cout<<a<<" "<<b<<'\n';
}

int getnum()
{
    static int num = 0;
    return ++num;
}

fun(getnum(),getnum());

{% endhighlight %}

c++并不保证函数参数中的执行顺序。所以这里可能会输出2 1也可能会输出1 2。

从基本层面上讲，线程间的先行比较简单，并且依赖与同步关系:如果操作A在一个线程上，与另一个线程上的操作B同步，那么A就线程间先行于B。这同样是一个传递关系：如果A线程间先行于B，并且B线程间先行于C，那么A就线程间先行于C。

### 5.3.3 原子操作的内存顺序

这里有六个内存序列选项可应用于对原子类型的操作：memory_order_relaxed,
memory_order_consume, memory_order_acquire, memory_order_release,
memory_order_acq_rel, 以及memory_order_seq_cst。除非你为特定的操作指定一个序列选项，要不内存序列选项对于所有原子类型默认都是memory_order_seq_cst。虽然有六个选项，但是它们仅代表三种内存模型：
* 排序一致序列(sequentially consistent)，
* 获取-释放序列(memory_order_consume, memory_order_acquire, memory_order_release和memory_order_acq_rel)
* 自由序列(memory_order_relaxed)。

x86或x86-64架构默认就是排序一致序列。

**排序一致序列**

默认序列命名为排序一致，是因为程序中的行为从任意角度去看，序列顺序都保持一致。如果原子类型实例上的所有操作都是序列一致的，那么一个多线程程序的行为，就以某种特殊的排序执行，好像单线程那样。

所有操作都不能重排序；如果你的代码，在一个线程中，将一个操作放在另一个操作前面，那么这个顺序就必须让其他所有的线程所了解。

从同步的角度看，对于同一变量，排序一致的存储操作同步相关于同步一致的载入操作。这就提供了一种对两个(以上)线程操作的排序约束，但是排序一致的功能要比排序约束大的多。所以，对于使用排序一致原子操作的系统上的任一排序一致的原子操作，都会在对值进行存储以后，再进行加载。

{% highlight c++ %}

std::atomic<bool> x,y;
std::atomic<int> z;

void write_x()
{
    x.store(true,std::memory_order_seq_cst);
}

void write_y()
{
    y.store(true,std::memory_order_seq_cst);
}

void read_x_then_y()
{
    //如果X为true但z没有增加，那么说明write_x操作先于write_y操作
    while(!x.load(std::memory_order_seq_cst));
    if(y.load(std::memory_order_seq_cst))
      ++z;
}

void read_y_then_x()
{
    while(!y.load(std::memory_order_seq_cst));
    if(x.load(std::memory_order_seq_cst))
      ++z;
}

std::thread t3(write_x);
std::thread t4(write_y);
std::thread t5(read_x_then_y);
std::thread t6(read_y_then_x);

t3.join();
t4.join();
t5.join();
t6.join();
    
assert(z.load() != 0);
{% endhighlight %}

如果write_x操作先发生于write_y，那么z不会增加，但在read_y_then_x中，z一定会增加，所以断点一定不会触发。

**非排序一致内存模型**

不同线程看到相同操作，不一定有着相同的顺序，还有对于不同线程的操作，都会整齐的，一个接着另一个执行的想法是需要摒弃的。不仅是你有没有考虑事情真的同时发生的问题，还有线程没必要去保证一致性。

不仅是要摒弃交错执行操作的想法，你还要放弃使用编译器或处理器重排指令的想法。在没有明确的顺序限制下，唯一的要求就是，所有线程都要统一对每一个独立变量的修改顺序。对不同变量的操作可以体现在不同线程的不同序列上，提供的值要与任意附加顺序限制保持一致。

**自由序列**

在原子类型上的操作以自由序列执行，没有任何同步关系。在同一线程中对于同一变量的操作还是服从先发执行的关系，但是这里不同线程几乎不需要相对的顺序。唯一的要求是，在访问同一线程中的单个原子变量不能重排序；当一个给定线程已经看到一个原子变量的特定值，线程随后的读操作就不会去检索变量较早的那个值。

{% highlight c++ %}

void write_x_then_y()
{
    x.store(true, std::memory_order_relaxed);
    y.store(true, std::memory_order_relaxed);
}

void read_y_then_x_relaxed()
{
    while (!y.load(std::memory_order_relaxed))
        ;
    if (x.load(std::memory_order_relaxed))
        z++;
}

std::thread t7(write_x_then_y);s
std::thread t8(read_y_then_x_relaxed);

t7.join();
t8.join();
assert(z.load() != 0);
{% endhighlight %}

这次assert可能会触发，因为加载x的操作可能读取到false，即使加载y的操作读取到true，并且存储x的操作先发与存储y的操作。x和y是两个不同的变量，所以这里没有顺序去保证每个操作产生相关值的可见性。

{% highlight c++ %}

std::atomic<int> x_relaxed(0),y_relaxed(0),z_relaxed(0);
std::atomic<bool> go(false);

const int loop_count = 10;

struct read_values
{
    int x;
    int y;
    int z;
};

read_values values1[loop_count];
read_values values2[loop_count];
read_values values3[loop_count];
read_values values4[loop_count];
read_values values5[loop_count];

void incresment(std::atomic<int>* var_to_inc,read_values* values)
{
    while(!go.load())
        std::this_thread::yield();
    for(int i = 0;i < loop_count; i++)
    {
        values[i].x = x_relaxed.load(std::memory_order_relaxed);
        values[i].y = y_relaxed.load(std::memory_order_relaxed);
        values[i].z = z_relaxed.load(std::memory_order_relaxed);
        var_to_inc->store(i+1,std::memory_order_relaxed);
        std::this_thread::yield();
    }
}

void read_value(read_values* values)
{
    while(!go.load())
        std::this_thread::yield();
    for(int i = 0;i < loop_count; i++)
    {
        values[i].x = x_relaxed.load(std::memory_order_relaxed);
        values[i].y = y_relaxed.load(std::memory_order_relaxed);
        values[i].z = z_relaxed.load(std::memory_order_relaxed);
        std::this_thread::yield();
    }    
}

void print(read_values* values)
{
    for(int i = 0; i < loop_count; i++)
    {
        if(i)
          std::cout<<',';
        std::cout<<"("<<values[i].x<<","<<values[i].y<<","<<values[i].z<<")";
    }
    std::cout<<'\n';
}

std::thread t9(incresment,&x_relaxed,values1);
std::thread t10(incresment,&y_relaxed,values2);
std::thread t11(incresment,&z_relaxed,values3);
std::thread t12(read_value,values4);
std::thread t13(read_value,values5);

go = true;

t9.join();
t10.join();
t11.join();
t12.join();
t13.join();

print(values5);
print(values4);
print(values3);
print(values2);
print(values1);
{% endhighlight %}

1. 第一组值中x增1，第二组值中y增1，并且第三组中z增1。
2. x元素只在给定集中增加，y和z也一样，但是增加是不均匀的，并且相对顺序在所有线程中都不同。
3. 线程3看不到x或y的任何更新；他能看到的只有z的更新。这并不妨碍别的线程观察z的更新，并同时观察x和y的更新。

为了了解自由序列是如何工作的，先将每一个变量想象成一个在独立房间中拿着记事本的人。他的记事本上是一组值的列表。你可以通过打电话的方式让他给你一个值，或让他写下一个新值。如果你告诉他写下一个新值，他会将这个新值写在表的最后。如果你让他给你一个值，他会从列表中读取一个值给你。

在你第一次与这个人交谈时，如果你问他要一个值，他可能会给你现在列表中的任意值。如果之后你再问他要一个值，它可能会再给你同一个值，或将列表后面的值给你，他不会给你列表上端的值。如果你让他写一个值，并且随后再问他要一个值，他要不就给你你刚告诉他的那个值，要不就是一个列表下端的值。

**获取-释放序列**

在这种序列模型中，原子加载就是获取(acquire)操作(memory_order_acquire)，原子存储就是释放(memory_order_release)操作，原子读-改-写操作(例如fetch_add()或exchange())在这里，不是“获取”，就是“释放”，或者两者兼有的操作(memory_order_acq_rel)。这里，同步在线程释放和获取间是成对的(pairwise)。释放操作与获取操作同步，这样就能读取已写入的值。这意味着不同线程看到的序列虽还是不同，但这些序列都是受限的。

{% highlight c++ %}

void write_x_release()
{
    x.store(true,std::memory_order_release);
}

void write_y_release()
{
    y.store(true,std::memory_order_release);
}

void read_x_then_y_acquire()
{
    while(!x.load(std::memory_order_acquire))
      ;
    if(y.load(std::memory_order_acquire))
      ++z;
}

void read_y_then_x_acquire()
{
    while(!y.load(std::memory_order_acquire))
      ;
    if(x.load(std::memory_order_acquire));
      ++z;
}

x = false;
y = false;
z = 0;

std::thread t14(write_x_release);
std::thread t15(write_y_release);
std::thread t16(read_x_then_y_acquire);
std::thread t17(read_y_then_x_acquire);
    
t14.join();
t15.join();
t16.join();
t17.join();

assert(z.load() != 0);
{% endhighlight %}

在这个例子中断言可能会触发(就如同自由排序那样)，因为可能在加载x和y的时候，读取到的是false。因为x和y是由不同线程写入，所以序列中的每一次释放到获取都不会影响到其他线程的操作。

{% highlight c++ %}

void write_x_then_y_release()
{
    x.store(true,std::memory_order_relaxed);
    y.store(true,std::memory_order_release);
}

void read_y_then_x_acquire1()
{
    while(!y.load(std::memory_order_acquire))
      ;
    if(x.load(std::memory_order_relaxed))
      ++z;
}

x = false;
y = false;
z = 0;

std::thread t18(write_x_then_y_release);
std::thread t19(read_y_then_x_acquire1);

t18.join();
t19.join();

assert(z.load() != 0);
{% endhighlight %}

因为这两个操作是由同一个线程完成的，所以存储x先行于加载y。对y的存储同步与对y的加载，存储x也就先行于对y的加载，并且扩展先行于x的读取。因此，加载x的值必为true，并且断言不会触发。

**与同步传递相关的获取-释放序列**

当A线程间先行于B，并且B线程间先行于C，那么A就线程间先行于C。这就意味着，获取-释放序列可以在若干线程间使用同步数据，甚至可以在“中间”线程接触到这些数据前，使用这些数据。

{% highlight c++ %}

std::atomic<int> source[5];
std::atomic<bool> sync1(false),sync2(false);

void thread_1()
{
    source[0].store(0,std::memory_order_relaxed);
    source[1].store(1,std::memory_order_relaxed);
    source[2].store(2,std::memory_order_relaxed);
    source[3].store(3,std::memory_order_relaxed);
    source[4].store(4,std::memory_order_relaxed);
    sync1.store(true,std::memory_order_release);    
}

void thread_2()
{
    while(!sync1.load(std::memory_order_acquire))
      ;
    sync2.store(true,std::memory_order_release);
}

void thread_3()
{
    while(!sync2.load(std::memory_order_acquire))
      ;
    assert(source[0].load(std::memory_order_relaxed) == 0);
    assert(source[1].load(std::memory_order_relaxed) == 1);
    assert(source[2].load(std::memory_order_relaxed) == 2);
    assert(source[3].load(std::memory_order_relaxed) == 3);
    assert(source[4].load(std::memory_order_relaxed) == 4);
}
{% endhighlight %}

thread_1存储数据到data的操作先行于thread_3中对data的加载，并且保证断言都不会触发。

sync1和sync2可以通过读改写操（memory_order_acq_rel）作合并成一个变量。

{% highlight c++ %}

std::atomic<int> sync(0);
void thread_1()
{
  // ...
  sync.store(1,std::memory_order_release);
}
void thread_2()
{
  int expected=1;
  while(!sync.compare_exchange_strong(expected,2,
    std::memory_order_acq_rel))
  expected=1;
}
void thread_3()
{
  while(sync.load(std::memory_order_acquire)<2);
  // ...
}

{% endhighlight %}

**获取-释放序列和memory_order_consume的数据相关性**

{% highlight c++ %}

struct X
{
    int i;
    std::string s;
};

std::atomic<X*> pp;
std::atomic<int> a;

void thread_x()
{
    X* x = new X();
    x->i = 1;
    x->s = "hello";
    a.store(99,std::memory_order_relaxed);
    pp.store(x,std::memory_order_release);
}

void use_x()
{
    X* x;
    while(!(x = pp.load(std::memory_order_consume)))
      ;
    assert(x->i == 1);
    assert(x->s == "hello");
    assert(a.load(std::memory_order_relaxed) == 99);    
}

{% endhighlight %}

尽管，对a的存储在存储pp之前，并且存储pp的操作标记为memory_order_release，加载pp的操作标记为memory_order_consume，这就意味着存储pp仅先行那些需要加载pp的操作。同样，也意味着X结构体中数据成员所在的断言语句，不会被触发，这是因为对x变量操作的表达式对加载pp的操作携带有依赖。另一方面，对于加载变量a的断言就不能确定是否会被触发；这个操作并不依赖于pp的加载操作，所以这里没法保证数据已经被读取。

使用 std::kill_dependecy() 来显式打破依赖链。 std::kill_dependency() 是一个简单的函数模
板，其会复制提供的参数给返回值，但是依旧会打破依赖链。

{% highlight c++ %}

int global_data[]={ … };
std::atomic<int> index;
void f()
{
  int i=index.load(std::memory_order_consume);
  do_something_with(global_data[std::kill_dependency(i)]);
}
{% endhighlight %}

当你拥有一个全局的只读数组，当其他线程对数组索引进行检索时，你使用的是std::memory_order_consume ，那么你可以使用 std::kill_dependency() 让编译器知道这里不需要重新读取该数组的内容。

### 5.3.4 释放队列与同步